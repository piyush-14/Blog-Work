
var documents = [{
    "id": 0,
    "url": "https://piyush-14.github.io/404.html",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "https://piyush-14.github.io/about/",
    "title": "About Me",
    "body": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. This website is powered by fastpages 1.       a blogging platform that natively supports Jupyter notebooks in addition to other formats.  &#8617;    "
    }, {
    "id": 2,
    "url": "https://piyush-14.github.io/categories/",
    "title": "Tags",
    "body": "Contents: {% if site. categories. size &gt; 0 %} {% for category in site. categories %} {% capture category_name %}{{ category | first }}{% endcapture %} {{ category_name }}{% endfor %}{% endif %} {% for category in site. categories %}  {% capture category_name %}{{ category | first }}{% endcapture %} &lt;h3 id = {{ category_name }} &gt;&lt;i class= fas fa-tags category-tags-icon &gt;&lt;/i&gt;&lt;/i&gt; {{ category_name }}&lt;/h3&gt;&lt;a name= {{ category_name | slugize }} &gt;&lt;/a&gt;{% for post in site. categories[category_name] %}{%- assign date_format = site. minima. date_format | default:  %b %-d, %Y  -%}&lt;article class= archive-item &gt; &lt;p class= post-meta post-meta-title &gt;&lt;a class= page-meta  href= {{ site. baseurl }}{{ post. url }} &gt;{{post. title}}&lt;/a&gt; • {{ post. date | date: date_format }}&lt;/p&gt;&lt;/article&gt;{% endfor %} {% endfor %}"
    }, {
    "id": 3,
    "url": "https://piyush-14.github.io/images/copied_from_nb/",
    "title": "",
    "body": "WarningDo not manually save images into this folder. This is used by GitHub Actions to automatically copy images.  Any images you save into this folder could be deleted at build time. "
    }, {
    "id": 4,
    "url": "https://piyush-14.github.io/2020/03/07/first-callback.html",
    "title": "First Callback",
    "body": "2020/03/07 - Fastai is a great library with great resources implemented in an intuitive style. There are various kinds of callbacks which makes the training of the model easier as well as interesting. There is still a concept of Runner which is talked about in the Fastai Deep Learning Part2 which is kind of hard to understand. But not anymore. Today we will go through the Runner class and try to understand its concepts under the hood. What are Callbacks? Callbacks are a little mystery object which helps the training of the model. In simple language Callbacks are the special type of functions which are used to inject special behavior at different places in the training loop. There are various things which we might want to do while training our model,like:       Print the loss and the accuracy metrics.          Record the Losses for each batch and plot them.          Find a good learning rate for the model.    All these things can be implemented with the help of Callbacks, in short, Callbacks help to make the training loop infinitely customizable like Sylvain Gugger said. No matter how good a thing is, it can always be improved. And the improvement is the Runner class. But to fully understand the improved version, you have to be familiar with the basics of the CallbackHandler and its limitations. These are some great resources to understand the Callbacks. So I would recommend you to go through these blog posts before reading further. Understanding the Callbacks Implementing Callbacks in Fastai After going through the above articles you must have noticed that the Callbacks has to inherit from the base Callback which has different methods of its own as seen below. It’s also worth noting that the only reason we inherit from this class is to handle the exceptions which might rise when someone calls a method onto a callback which is not defined in its scope. class Callback(): def begin_fit(self, learn): self. learn = learn return True def after_fit(self): return True def begin_epoch(self, epoch): self. epoch=epoch return True def begin_validate(self): return True def after_epoch(self): return True def begin_batch(self, xb, yb): self. xb,self. yb = xb,yb return True def after_loss(self, loss): self. loss = loss return True def after_backward(self): return True def after_step(self): return True Suppose you define a TestCallback which will stop the execution once the number of iterations is greater than 10. The Callback is defined as seen below. class TestCallback(Callback): def begin_fit(self,learn): super(). begin_fit(learn) self. n_iters = 0 return True def after_step(self): self. n_iters += 1 print(self. n_iters) if self. n_iters&gt;=10: self. learn. stop = True return True So if we call a method like “after_loss” on the TestCallback then it would look for the method in its own scope and if not found then will look for the super() class which is Callback and would perform that method. Thus, an error is averted. Hence this inheritance has to be improved in future. Another problem which needs to be addressed is the duplication of the code in the CallbackHandler() which can be avoided with a different class. Now let’s have a look at the Runner class. The Runner class can be seen below has the training loops inside it with only callbacks and the callback functions initialised. It can look a bit intimidating but don’t worry we will break down the class and get through it. The main magic is happening inside the __init__( ) as well as the __call__( ) methods. class Runner(): def __init__(self, cbs=None, cb_funcs=None): cbs = listify(cbs) # converts the arguments into type list. for cbf in listify(cb_funcs): cb = cbf() setattr(self, cb. name, cb) cbs. append(cb) self. stop,self. cbs = False,[TrainEvalCallback()]+cbs @property def opt(self): return self. learn. opt @property def model(self): return self. learn. model @property def loss_func(self): return self. learn. loss_func @property def data(self): return self. learn. data def one_batch(self, xb, yb): self. xb,self. yb = xb,yb if self('begin_batch'): return self. pred = self. model(self. xb) if self('after_pred'): return self. loss = self. loss_func(self. pred, self. yb) if self('after_loss') or not self. in_train: return self. loss. backward() if self('after_backward'): return self. opt. step() if self('after_step'): return self. opt. zero_grad() def all_batches(self, dl): self. iters = len(dl) for xb,yb in dl: if self. stop: break self. one_batch(xb, yb) self('after_batch') self. stop=False def fit(self, epochs, learn): self. epochs,self. learn = epochs,learn try: for cb in self. cbs: cb. set_runner(self) if self('begin_fit'): return for epoch in range(epochs): self. epoch = epoch if not self('begin_epoch'): self. all_batches(self. data. train_dl) with torch. no_grad(): if not self('begin_validate'): self. all_batches(self. data. valid_dl) if self('after_epoch'): break finally: self('after_fit') self. learn = None def __call__(self, cb_name): for cb in sorted(self. cbs, key=lambda x: x. _order): f = getattr(cb, cb_name, None) if f and f(): return True return False Upgraded Callback Class: class Callback(): _order=0 def set_runner(self, run): self. run=run def __getattr__(self, k): return getattr(self. run, k) @property def name(self): name = re. sub(r'Callback$', '', self. __class__. __name__) return camel2snake(name or 'callback') "
    }, {
    "id": 5,
    "url": "https://piyush-14.github.io/2020/02/29/my_02_fully_connected.html",
    "title": "Title",
    "body": "2020/02/29 -                 %load_ext autoreload%autoreload 2%matplotlib inline  The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload        import torch,pickle, gzip,math, matplotlib as mplimport matplotlib. pyplot as pltfrom torch import tensorfrom fastai import datasetsfrom pathlib import Path          mnist_url = &#39;http://deeplearning. net/data/mnist/mnist. pkl&#39;def get_data(): path = datasets. download_data(mnist_url , ext = &#39;. gz&#39;) with gzip. open(path,&#39;rb&#39;) as f:  ((x_train,y_train), (x_valid,y_valid),_) = pickle. load(f, encoding= &#39;latin-1&#39;) return map(tensor, (x_train,y_train, x_valid,y_valid))def normalize(x,m,s): return (x-m)/s          (x_train,y_train, x_valid,y_valid) = get_data()  Downloading http://deeplearning. net/data/mnist/mnist. pkl        n,m,= x_train. shape ;n,m  (50000, 784)        train_mean = x_train. mean()train_std = x_train. std()train_mean, train_std  (tensor(0. 1304), tensor(0. 3073))        def test_near_zero(a): assert a. abs()&lt;1e-03, f&quot;Near Zero: {a}&quot;          # normalize the train and valid datasets# normalize the valid dataset with the mean and std obtained by the train mean and stdx_train = normalize(x_train ,train_mean, train_std)# valid setx_valid = normalize(x_valid, train_mean, train_std)          x_train. mean(), x_train. std()  (tensor(0. 0001), tensor(1. ))        x_valid. mean(), x_valid. std()  (tensor(-0. 0057), tensor(0. 9924))        # test_near_zero(x_valid. mean())# test_near_zero(1-x_valid. std())# x_valid. std(). abs(),1+x_valid. mean(). abs()          c = y_train. max()+1;c  tensor(10)        # hidden unitsnh = 50n,m,c  (50000, 784, tensor(10))  Define the model       # kaiming init simplifiedw1 = torch. randn(m,nh)/math. sqrt(m)b1 = torch. zeros(nh)w2 = torch. randn(nh,1)/math. sqrt(nh)b2 = torch. zeros(1)w1. mean(), w1. std() #should be zero and 1/math. sqrt(m)test_near_zero(w1. std()-1/math. sqrt(m))          # Linear Layerdef lin(x,w,b): return x@w + b          # Reludef relu(x): return x. clamp_min(0. )          t1 = lin(x_valid, w1,b1)t1. mean(), t1. std() # this is exactly what we had expected.   ---------------------------------------------------------------------------NameError                 Traceback (most recent call last)&lt;ipython-input-19-ff7a4425a9ca&gt; in &lt;module&gt;()----&gt; 1 t1 = lin(x_valid, w1,b1)   2 t1. mean(), t1. std() # this is exactly what we had expected. NameError: name &#39;w1&#39; is not defined        t1_relu = relu(t1)t1_relu. mean(), t1_relu. std() # and mean and the std is different because of the non-linearity of the Relu.   (tensor(0. 4469), tensor(0. 6575))  Improving the kaiming init       w1 = torch. randn(m,nh)*math. sqrt(2/m)b1 = torch. zeros(nh)w2 = torch. randn(nh,1)*math. sqrt(2/nh)b2 = torch. zeros(1)# Kaiming init considers the relu activation function and improve the std. # def Relu(x): return x. clamp_min(0. ) - 0. 5t1 = relu(lin(x_valid, w1, b1))t1. mean(), t1. std()  (tensor(0. 5362), tensor(0. 7973))        from torch. nn import init          # w1 = torch. zeros(m,nh)# b1 = torch. zeros(nh)# w1 = init. kaiming_normal_(w1, mode = &#39;fan_out&#39;)          w1. mean(), w1. std()  (tensor(-0. 0001), tensor(0. 0507))        import torch. nn          torch. nn. functional. linear??          torch. nn. Linear(m,nh). weight. shape  torch. Size([50, 784])        w1. shape,b1. shape,x_train. shape  (torch. Size([784, 50]), torch. Size([50]), torch. Size([50000, 784]))        t1 = lin(x_valid,w1,b1)t1. shape  torch. Size([10000, 50])        def model(xb): l1 = lin(xb,w1,b1) l2 = relu(l1) out = lin(l2,w2,b2) return out          preds = model(x_valid)          def mse(out, target): return (out. squeeze(-1) - target). pow(2). mean()          loss = mse(preds,y_valid);loss  tensor(25. 6047)        preds. shape, y_valid. shape  (torch. Size([10000, 1]), torch. Size([10000]))        y_valid. unsqueeze(1). shape[0]  10000  Gradients and Backward Pass       def mse_grad(out,tar): out. g = 2. * (out - tar. unsqueeze(1))/out. shape[0]          def relu_grad(inp,out): inp. g = (inp&gt;0). float() * out. g          def lin_grad(inp, out, w, b): inp. g = out. g @ w. t() w. g = (inp * out. g). sum() b. g = out. g. sum()          t1 = lin(x_valid[:10], w1, b1)t2 = relu(t1)    "
    }, {
    "id": 6,
    "url": "https://piyush-14.github.io/jupyter/2020/02/20/test.html",
    "title": "Fastpages Notebook Blog Post",
    "body": "2020/02/20 -           About This notebook is a demonstration of some of capabilities of fastpages with notebooks. With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! Front Matter : Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example: Setting toc: true will automatically generate a table of contentsSetting badges: true will automatically include GitHub and Google Colab links to your notebook. Setting comments: true will enable commenting on your blog post, powered by utterances. More details and options for front matter can be viewed on the front matter section of the README. Markdown Shortcuts : put a #hide flag at the top of any cell you want to completely hide in the docs put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it:              #collapse-hideimport pandas as pdimport altair as alt       put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it:              #collapse-showcars = &#39;https://vega. github. io/vega-datasets/data/cars. json&#39;movies = &#39;https://vega. github. io/vega-datasets/data/movies. json&#39;sp500 = &#39;https://vega. github. io/vega-datasets/data/sp500. csv&#39;stocks = &#39;https://vega. github. io/vega-datasets/data/stocks. csv&#39;flights = &#39;https://vega. github. io/vega-datasets/data/flights-5k. json&#39;       Interactive Charts With Altair : Charts made with Altair remain interactive.  Example charts taken from this repo, specifically this notebook. Example 1: DropDown :       # single-value selection over [Major_Genre, MPAA_Rating] pairs# use specific hard-wired values as the initial selected valuesselection = alt. selection_single(  name=&#39;Select&#39;,  fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;],  init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;},  bind={&#39;Major_Genre&#39;: alt. binding_select(options=genres), &#39;MPAA_Rating&#39;: alt. binding_radio(options=mpaa)}) # scatter plot, modify opacity based on selectionalt. Chart(movies). mark_circle(). add_selection(  selection). encode(  x=&#39;Rotten_Tomatoes_Rating:Q&#39;,  y=&#39;IMDB_Rating:Q&#39;,  tooltip=&#39;Title:N&#39;,  opacity=alt. condition(selection, alt. value(0. 75), alt. value(0. 05)))    Example 2: Tooltips :       alt. Chart(movies). mark_circle(). add_selection(  alt. selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;])). encode(  x=&#39;Rotten_Tomatoes_Rating:Q&#39;,  y=alt. Y(&#39;IMDB_Rating:Q&#39;, axis=alt. Axis(minExtent=30)), # use min extent to stabilize axis title placement  tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;]). properties(  width=600,  height=400)    Example 3: More Tooltips :       # select a point for which to provide details-on-demandlabel = alt. selection_single(  encodings=[&#39;x&#39;], # limit selection to x-axis value  on=&#39;mouseover&#39;, # select on mouseover events  nearest=True,  # select data point nearest the cursor  empty=&#39;none&#39;   # empty selection includes no data points)# define our base line chart of stock pricesbase = alt. Chart(). mark_line(). encode(  alt. X(&#39;date:T&#39;),  alt. Y(&#39;price:Q&#39;, scale=alt. Scale(type=&#39;log&#39;)),  alt. Color(&#39;symbol:N&#39;))alt. layer(  base, # base line chart    # add a rule mark to serve as a guide line  alt. Chart(). mark_rule(color=&#39;#aaa&#39;). encode(    x=&#39;date:T&#39;  ). transform_filter(label),    # add circle marks for selected time points, hide unselected points  base. mark_circle(). encode(    opacity=alt. condition(label, alt. value(1), alt. value(0))  ). add_selection(label),  # add white stroked text to provide a legible background for labels  base. mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2). encode(    text=&#39;price:Q&#39;  ). transform_filter(label),  # add text labels for stock prices  base. mark_text(align=&#39;left&#39;, dx=5, dy=-5). encode(    text=&#39;price:Q&#39;  ). transform_filter(label),    data=stocks). properties(  width=700,  height=400)    Data Tables : You can display tables per the usual way in your blog:       movies = &#39;https://vega. github. io/vega-datasets/data/movies. json&#39;df = pd. read_json(movies)# display table with pandasdf[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;,   &#39;Production_Budget&#39;, &#39;IMDB_Rating&#39;]]. head()           Title   Worldwide_Gross   Production_Budget   IMDB_Rating         0   The Land Girls   146083. 0   8000000. 0   6. 1       1   First Love, Last Rites   10876. 0   300000. 0   6. 9       2   I Married a Strange Person   203134. 0   250000. 0   6. 8       3   Let's Talk About Sex   373615. 0   300000. 0   NaN       4   Slam   1087521. 0   1000000. 0   3. 4     Images : Local Images : You can reference local images and they will be copied and rendered on your blog automatically.  You can include these with the following markdown syntax: ![](my_icons/fastai_logo. png) Remote Images : Remote images can be included with the following markdown syntax: ![](https://image. flaticon. com/icons/svg/36/36686. svg) Animated Gifs : Animated Gifs work, too! ![](https://upload. wikimedia. org/wikipedia/commons/7/71/ChessPawnSpecialMoves. gif) Captions : You can include captions with markdown images like this: ![](https://www. fast. ai/images/fastai_paper/show_batch. png  Credit: https://www. fast. ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/ ) Other Elements Tweetcards : Typing &gt; twitter: https://twitter. com/jakevdp/status/1204765621767901185?s=20 will render this:Altair 4. 0 is released! https://t. co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t. co/roXmzcsT58 . . . read on for some highlights. pic. twitter. com/vWJ0ZveKbZ &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Youtube Videos : Typing &gt; youtube: https://youtu. be/XfoYk_Z5AkI will render this: Boxes / Callouts : Typing &gt; Warning: There will be no second warning! will render this:    Warning: There will be no second warning! Typing &gt; Important: Pay attention! It's important. will render this:    Important: Pay attention! It&#8217;s important. Typing &gt; Tip: This is my tip. will render this:    Tip: This is my tip. Typing &gt; Note: Take note of this. will render this:    Note: Take note of this. Typing &gt; Note: A doc link to [an example website: fast. ai](https://www. fast. ai/) should also work fine. will render in the docs:    Note: A doc link to an example website: fast. ai should also work fine. Footnotes : You can have footnotes in notebooks just like you can with markdown. For example, here is a footnote 1. This is the footnote. &#8617; "
    }, {
    "id": 7,
    "url": "https://piyush-14.github.io/markdown/2020/01/14/test-markdown-post.html",
    "title": "Example Markdown Post",
    "body": "2020/01/14 - Basic setup: Jekyll requires blog post files to be named according to the following format: YEAR-MONTH-DAY-filename. md Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. . md is the file extension for markdown files. The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. Basic formatting: You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: Lists: Here’s a list:  item 1 item 2And a numbered list:  item 1 item 2Boxes and stuff:  This is a quotation    You can include alert boxes…and…    You can include info boxesImages: Code: General preformatted text: # Do a thingdo_thing()Python code and output: # Prints '2'print(1+1)2Tables:       Column 1   Column 2         A thing   Another thing   Tweetcards: Altair 4. 0 is released! https://t. co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t. co/roXmzcsT58 . . . read on for some highlights. pic. twitter. com/vWJ0ZveKbZ &mdash; Jake VanderPlas (@jakevdp) December 11, 2019Footnotes:       This is the footnote.  &#8617;    "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')
    this.metadataWhitelist = ['position']

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}